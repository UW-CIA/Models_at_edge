{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vae at edge | 2 implementations",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nT_WpFbKe0CU"
      },
      "source": [
        "**The VAE implmentation we used**\n",
        "\n",
        "trained and ready for export"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKqO-tWaeyc8"
      },
      "source": [
        "#!pip install pyod\n",
        "#converting vae to a tf lite interpreter \n",
        "import tensorflow as tf\n",
        "from pyod.models.vae import VAE\n",
        "from pyod.models.auto_encoder import AutoEncoder\n",
        "from pyod.utils.data import generate_data\n",
        "\n",
        "model = VAE([1,16],[16,1],epochs=10) \n",
        "X_train, y_train = generate_data(behaviour='new', n_features=300, train_only=True)\n",
        "model.fit(X_train)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlRkTS55fOac"
      },
      "source": [
        "export pyod to tflite "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGqeVM-0fMw-"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model.model_)\n",
        "converter.allow_custom_ops = False\n",
        "converter.target_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\n",
        "                        tf.lite.OpsSet.SELECT_TF_OPS]\n",
        "converter.target_spec.supported_ops=[  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\n",
        "                                      tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\n",
        "]\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "open(\"pyod_converted_model.tflite\", \"wb\").write(tflite_model)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HE09EXuydt6U"
      },
      "source": [
        "**Common VAE Implementation**\n",
        "\n",
        "trained and ready for export\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiBKr0JBZ1hP",
        "outputId": "10795234-81f4-4539-8a0b-e7eddef05bab"
      },
      "source": [
        "#ref https://github.com/s-omranpour/X-VAE-keras/blob/e5ba984b5eff58f922db4442102a987619cecdc2/VAE/VAE.py\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Lambda, Input, Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.losses import mse, binary_crossentropy\n",
        "from tensorflow.keras import backend as K\n",
        "import numpy as np \n",
        "import tensorflow as tf\n",
        "\n",
        "xx, yy = np.meshgrid(np.linspace(-7, 7, 100), np.linspace(-7, 7, 100))\n",
        "\n",
        "def make_model(SIZE=28, LATENT_DIM=10, LR=1e-4, BETA=1.):\n",
        "    encoder_inputs = layers.Input(shape=(SIZE, SIZE, 1), name='encoder_input')\n",
        "    e = layers.Conv2D(filters=16,kernel_size=5,padding='SAME',activation='relu',strides=(2,2))(encoder_inputs)\n",
        "    e = layers.BatchNormalization()(e)\n",
        "    e = layers.Conv2D(filters=32,kernel_size=5,padding='SAME',activation='relu',strides=(2,2))(e)\n",
        "    e = layers.BatchNormalization()(e)\n",
        "    e = layers.Flatten()(e)\n",
        "    z_mean = layers.Dense(LATENT_DIM, name='z_mean')(e)\n",
        "    z_log_var = layers.Dense(LATENT_DIM, name='z_log_var')(e)\n",
        "    encoder = k.Model(inputs=encoder_inputs, outputs=[z_mean, z_log_var], name='encoder')\n",
        "\n",
        "\n",
        "    decoder_inputs = layers.Input(shape=(LATENT_DIM,), name='decoder_input')\n",
        "    d = layers.Dense(units=7*7*4,activation='relu')(decoder_inputs)\n",
        "    d = layers.Reshape((7,7,4))(d)\n",
        "    d = layers.Conv2DTranspose(filters=16,kernel_size=4,strides=(2, 2), padding=\"SAME\", activation='relu')(d)\n",
        "    d = layers.Conv2DTranspose(filters=32,kernel_size=4,strides=(2, 2), padding=\"SAME\", activation='relu')(d)\n",
        "    decoded = layers.Conv2DTranspose(filters=1, kernel_size=3,strides=(1, 1), padding=\"SAME\")(d)\n",
        "    decoder = k.Model(inputs=decoder_inputs, outputs=decoded, name='decoder')\n",
        "\n",
        "\n",
        "    def sample(inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        epsilon = tf.random.normal(shape=tf.shape(z_mean))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "    sampler = layers.Lambda(sample)\n",
        "    z = sampler([z_mean, z_log_var])\n",
        "    vae = k.Model(inputs=encoder_inputs, outputs=decoder(z), name='vae')\n",
        "\n",
        "    def compute_kernel(x, y):\n",
        "        x_size = tf.shape(x)[0]\n",
        "        y_size = tf.shape(y)[0]\n",
        "        dim = tf.shape(x)[1]\n",
        "        tiled_x = tf.tile(tf.reshape(x, [x_size, 1, dim]), [1, y_size, 1])\n",
        "        tiled_y = tf.tile(tf.reshape(y, [1, y_size, dim]), [x_size, 1, 1])\n",
        "        return tf.exp(-tf.reduce_mean(tf.square(tiled_x - tiled_y), axis=2) / tf.cast(dim, tf.float32))\n",
        "\n",
        "\n",
        "    def compute_mmd(x, y):\n",
        "        x_kernel = compute_kernel(x, x)\n",
        "        y_kernel = compute_kernel(y, y)\n",
        "        xy_kernel = compute_kernel(x, y)\n",
        "        return tf.reduce_mean(x_kernel) + tf.reduce_mean(y_kernel) - 2 * tf.reduce_mean(xy_kernel)\n",
        "\n",
        "    true_samples = tf.random.normal(shape=tf.shape(z))\n",
        "    loss_mmd = compute_mmd(true_samples, z)\n",
        "    vae.add_loss(loss_mmd*BETA)\n",
        "        \n",
        "    vae.compile(loss='mse', optimizer=k.optimizers.Adam(LR), metrics=['mse'])\n",
        "    return encoder, decoder , vae\n",
        "\n",
        "\n",
        "latent_dim=2\n",
        "hidden_activation='relu'\n",
        "output_activation='sigmoid'\n",
        "loss=mse\n",
        "optimizer='adam'\n",
        "epochs=100\n",
        "batch_size=32\n",
        "dropout_rate=0.2\n",
        "l2_regularizer=0.1\n",
        "validation_size=0.1\n",
        "preprocessing=True\n",
        "verbose=1\n",
        "random_state=None\n",
        "contamination=0.1\n",
        "gamma=1.0\n",
        "capacity=0.0\n",
        "X=xx\n",
        "n_samples_=X.shape[0]\n",
        "n_features_ =X.shape[1]\n",
        "def sampling( args):\n",
        "        \"\"\"Reparametrisation by sampling from Gaussian, N(0,I)\n",
        "        To sample from epsilon = Norm(0,I) instead of from likelihood Q(z|X)\n",
        "        with latent variables z: z = z_mean + sqrt(var) * epsilon\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        args : tensor\n",
        "            Mean and log of variance of Q(z|X).\n",
        "    \n",
        "        Returns\n",
        "        -------\n",
        "        z : tensor\n",
        "            Sampled latent variable.\n",
        "        \"\"\"\n",
        "\n",
        "        z_mean, z_log = args\n",
        "        batch = K.shape(z_mean)[0]  # batch size\n",
        "        dim = K.int_shape(z_mean)[1]  # latent dimension\n",
        "        epsilon = K.random_normal(shape=(batch, dim))  # mean=0, std=1.0\n",
        "\n",
        "        return z_mean + K.exp(0.5 * z_log) * epsilon\n",
        "def vae_loss(inputs, outputs, z_mean, z_log):\n",
        "    \"\"\" Loss = Recreation loss + Kullback-Leibler loss\n",
        "    for probability function divergence (ELBO).\n",
        "    gamma > 1 and capacity != 0 for beta-VAE\n",
        "    \"\"\"\n",
        "\n",
        "    reconstruction_loss = loss(inputs, outputs)\n",
        "    reconstruction_loss *=n_features_\n",
        "    kl_loss = 1 + z_log - K.square(z_mean) - K.exp(z_log)\n",
        "    kl_loss = -0.5 * K.sum(kl_loss, axis=-1)\n",
        "    kl_loss = gamma * K.abs(kl_loss - capacity)\n",
        "\n",
        "    return K.mean(reconstruction_loss + kl_loss)\n",
        "def make_modelv(): \n",
        "        inputs = Input(shape=(n_features_,))\n",
        "        # Input layer\n",
        "        layer = Dense(n_features_, activation=hidden_activation)(\n",
        "            inputs)\n",
        "        # Hidden layers\n",
        "        for neurons in [16,1]:\n",
        "            layer = Dense(neurons, activation=hidden_activation,\n",
        "                          activity_regularizer=l2(l2_regularizer))(layer)\n",
        "            layer = Dropout(dropout_rate)(layer)\n",
        "        # Create mu and sigma of latent variables\n",
        "        z_mean = Dense(latent_dim)(layer)\n",
        "        z_log = Dense(latent_dim)(layer)\n",
        "        # Use parametrisation sampling\n",
        "        z = Lambda(sampling, output_shape=(latent_dim,))(\n",
        "            [z_mean, z_log])\n",
        "        # Instantiate encoder\n",
        "        encoder = Model(inputs, [z_mean, z_log, z])\n",
        "        if verbose >= 1:\n",
        "            encoder.summary()\n",
        "\n",
        "        # Build Decoder\n",
        "        latent_inputs = Input(shape=(latent_dim,))\n",
        "        # Latent input layer\n",
        "        layer = Dense(latent_dim, activation=hidden_activation)(\n",
        "            latent_inputs)\n",
        "        # Hidden layers\n",
        "        for neurons in [1,16]:\n",
        "            layer = Dense(neurons, activation=hidden_activation)(layer)\n",
        "            layer = Dropout(dropout_rate)(layer)\n",
        "        # Output layer\n",
        "        outputs = Dense(n_features_, activation=output_activation)(\n",
        "            layer)\n",
        "        # Instatiate decoder\n",
        "        decoder = Model(latent_inputs, outputs)\n",
        "        if verbose >= 1:\n",
        "            decoder.summary()\n",
        "        # Generate outputs\n",
        "        outputs = decoder(encoder(inputs)[2])\n",
        "\n",
        "        # Instantiate VAE\n",
        "        vae = Model(inputs, outputs)\n",
        "        vae.add_loss(vae_loss(inputs, outputs, z_mean, z_log))\n",
        "        vae.compile(optimizer=optimizer)\n",
        "        return vae \n",
        "\n",
        "#converting vae to a tf lite interpreter \n",
        "import tensorflow as tf\n",
        "#_,_,\n",
        "model = make_modelv()#AutoEncoder() #VAE([1,16],[16,1],epochs=10) \n",
        "#X_train, y_train = generate_data(behaviour='new', n_features=300, train_only=True)\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "(train_images, y_train), (test_images, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "train_images = train_images.reshape((28,1)).astype('float32')\n",
        "test_images = test_images.reshape((28,1)).astype('float32')\n",
        "train_images /= 255.\n",
        "test_images /= 255.\n",
        "'''\n",
        "n_samples = 200\n",
        "outliers_fraction = 0.25\n",
        "clusters_separation = [0]\n",
        "\n",
        "# Compare given detectors under given settings\n",
        "# Initialize the data\n",
        "\n",
        "n_inliers = int((1. - outliers_fraction) * n_samples)\n",
        "n_outliers = int(outliers_fraction * n_samples)\n",
        "ground_truth = np.zeros(n_samples, dtype=int)\n",
        "ground_truth[-n_outliers:] = 1\n",
        "model.fit(xx, xx, epochs=1, batch_size=128, verbose=0)#X_train)  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 100)          10100       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 16)           1616        dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 16)           0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1)            17          dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 1)            0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            4           dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 2)            4           dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 2)            0           dense_3[0][0]                    \n",
            "                                                                 dense_4[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 11,741\n",
            "Trainable params: 11,741\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 2)]               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 2)                 6         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 3         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 16)                32        \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 100)               1700      \n",
            "=================================================================\n",
            "Total params: 1,741\n",
            "Trainable params: 1,741\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3ff0662150>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxcmjXkEeBnN"
      },
      "source": [
        "common vae export to tflite \n",
        "\n",
        "Input: Model \n",
        "\n",
        "Output: tflite file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmoWK6zTZ1fI",
        "outputId": "5baf3b84-6623-44e3-a496-ce8ff9c3f757"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.allow_custom_ops = False\n",
        "converter.target_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\n",
        "                        tf.lite.OpsSet.SELECT_TF_OPS]\n",
        "converter.target_spec.supported_ops=[  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\n",
        "                                      tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\n",
        "]\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "open(\"converted_model.tflite\", \"wb\").write(tflite_model)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpw3a65zmw/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpw3a65zmw/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59232"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mL5pTe2JefnN"
      },
      "source": [
        "**Running tflite model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXR3K3BxZ1aA",
        "outputId": "e916574e-1d16-4558-e1f3-d113c935e430"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load the TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_path=\"pyod_converted_model.tflite\")#converted_model.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Test the model on random input data.\n",
        "input_shape = input_details[0]['shape']\n",
        "input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
        "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "\n",
        "interpreter.invoke()\n",
        "\n",
        "# The function `get_tensor()` returns a copy of the tensor data.\n",
        "# Use `tensor()` in order to get a pointer to the tensor.\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "print(output_data)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.3521298  0.2926765  0.32065654 0.3306433  0.29287452 0.3065982\n",
            "  0.3014711  0.3048416  0.32357097 0.318429   0.3296155  0.31570414\n",
            "  0.29687485 0.32240692 0.3058303  0.3303503  0.30831164 0.3347178\n",
            "  0.34102196 0.33371425 0.3509057  0.29285443 0.29003552 0.3483403\n",
            "  0.3421046  0.32886195 0.29342467 0.3275562  0.3182295  0.32856604\n",
            "  0.29579797 0.30743098 0.3033597  0.3252707  0.3083835  0.31825036\n",
            "  0.3012674  0.34630418 0.31980848 0.29922867 0.34561753 0.33646673\n",
            "  0.34095085 0.32214624 0.32346812 0.29671413 0.3478047  0.34523755\n",
            "  0.3438179  0.32386684 0.31123585 0.3102281  0.3391952  0.31694394\n",
            "  0.35324875 0.3415819  0.31023216 0.30788547 0.32678473 0.3077941\n",
            "  0.30900517 0.325284   0.34328794 0.33139187 0.33744705 0.34429824\n",
            "  0.2990842  0.3357215  0.33033252 0.30905956 0.3467026  0.32437938\n",
            "  0.3146236  0.34470195 0.32060835 0.30635837 0.35185832 0.34855193\n",
            "  0.35217303 0.31467423 0.30161166 0.32443106 0.34401575 0.31414723\n",
            "  0.3387174  0.32425067 0.30144906 0.3042014  0.3270162  0.31103122\n",
            "  0.33518857 0.29726264 0.35001045 0.32623506 0.32479107 0.32376355\n",
            "  0.29970735 0.31390738 0.353635   0.33930776 0.32350808 0.31419533\n",
            "  0.30884254 0.32349792 0.32868564 0.31968188 0.33760506 0.31566715\n",
            "  0.29941005 0.34796113 0.3291905  0.31122255 0.29363465 0.2903998\n",
            "  0.3192963  0.29683706 0.31876054 0.30811518 0.3192523  0.29735652\n",
            "  0.3346962  0.29690653 0.34496123 0.34005845 0.30770746 0.31253564\n",
            "  0.34256738 0.29468036 0.33486408 0.2915505  0.31997502 0.30004543\n",
            "  0.35103303 0.30780798 0.2939893  0.30195084 0.33772063 0.33964854\n",
            "  0.31552726 0.35038218 0.3315944  0.34233642 0.32080925 0.33292356\n",
            "  0.35050425 0.33166322 0.3108195  0.29020256 0.35025892 0.30085933\n",
            "  0.33127344 0.30516088 0.34137762 0.3461848  0.33063835 0.3428973\n",
            "  0.3023641  0.34753013 0.31149787 0.34698656 0.339456   0.31833255\n",
            "  0.34294653 0.31759995 0.35139465 0.3195241  0.28979093 0.35241625\n",
            "  0.31217438 0.2980817  0.3063206  0.33684695 0.31882152 0.30379012\n",
            "  0.29242635 0.33799657 0.30626267 0.34479523 0.30854625 0.30730867\n",
            "  0.2911677  0.3193143  0.31907284 0.32073832 0.3470021  0.29143333\n",
            "  0.3221689  0.33066237 0.3032903  0.35150284 0.35016322 0.34237662\n",
            "  0.3429253  0.3115849  0.32730716 0.3460674  0.2969221  0.33433875\n",
            "  0.32525727 0.3289668  0.35438165 0.35407573 0.339347   0.318116\n",
            "  0.31372744 0.29809397 0.35016587 0.30823892 0.29082552 0.3365493\n",
            "  0.30437076 0.30067256 0.3498022  0.3485924  0.3362756  0.34290397\n",
            "  0.32808295 0.3157724  0.30378923 0.30414885 0.31909692 0.29830486\n",
            "  0.31115142 0.2997591  0.33600834 0.3037133  0.34168333 0.3141681\n",
            "  0.33275294 0.317936   0.33638448 0.3403515  0.32807297 0.32705837\n",
            "  0.31268328 0.34521052 0.2957234  0.3012539  0.35221523 0.3464871\n",
            "  0.32282522 0.3513928  0.29692668 0.30098778 0.34696212 0.3398748\n",
            "  0.34408528 0.3151062  0.33074898 0.30737793 0.3486289  0.33034834\n",
            "  0.2914178  0.34163773 0.30496854 0.32339045 0.33805728 0.31590658\n",
            "  0.3233501  0.32250333 0.29480946 0.32618916 0.33252472 0.33259243\n",
            "  0.35366356 0.30818275 0.32348156 0.29112428 0.2937115  0.29669428\n",
            "  0.34313175 0.31828746 0.3212496  0.32455096 0.3532846  0.3301012\n",
            "  0.34567523 0.31580693 0.34346652 0.30923557 0.2970206  0.3066959\n",
            "  0.34072605 0.3148229  0.30099154 0.3291881  0.34524137 0.34016114\n",
            "  0.28962988 0.30905908 0.2978425  0.31950033 0.3021484  0.3370775\n",
            "  0.32284284 0.29627615 0.30503345 0.30993453 0.34326166 0.3113206 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiJVIcc7F80h",
        "outputId": "7c8f3180-1025-44d2-a0aa-ec34848c2ba6"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "converted_model.tflite\tmodel.h5  pyod_converted_model.tflite  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}